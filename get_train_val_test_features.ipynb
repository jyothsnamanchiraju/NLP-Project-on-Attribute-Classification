{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"get_train_val_test_features.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNuclzIoKpiEO2dj5CVftTh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wEJB3lqkPr11"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import json\n","\n","def get_features(features_file, targets_file, train_val_test_indices_file):\n","  \n","  feats = []\n","  train_feats = []\n","  train_labels = []\n","  val_feats = []\n","  val_labels = []\n","  test_feats = []\n","  test_labels = []\n","\n","  # Load train val test indices file\n","  f = open(train_val_test_indices_file)\n","  c_indices = json.load(f)\n","\n","  # Load targets file\n","  c_targets = np.load(targets_file)\n","  train_labels = np.take(c_targets, c_indices['train'], axis=0)\n","  val_labels = np.take(c_targets, c_indices['val'], axis=0)\n","  test_labels = np.take(c_targets, c_indices['test'], axis=0)\n","  \n","  if (features_file.find('.csv') != -1):   # Filename has .csv \n","    # Load features file\n","    df = pd.read_csv(features_file) # Read csv into pandas dataframe\n","    df = df.iloc[:,2:] # Remove the first two columns (indices,title text)\n","    feats = df.to_numpy() # Convert data to numpy        \n","  else :\n","    feats = np.load(features_file)\n","\n","  train_feats = np.take(feats, c_indices['train'], axis=0)\n","  val_feats = np.take(feats, c_indices['val'], axis=0)\n","  test_feats = np.take(feats, c_indices['test'], axis=0)\n","    \n","\n","  return (train_feats,train_labels,val_feats,val_labels,test_feats,test_labels)\n","\n"]},{"cell_type":"code","source":["def fmtF1Score(f1Score):\n","  return str(format(f1Score,\".3f\"))"],"metadata":{"id":"O21kPBHoBfUV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC \n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n","\n","def train_and_eval(model_name,model_hypers,train_feats,train_labels,val_feats,val_labels):\n","  best_val_scores = 0\n","  best_val_model_params = [0]\n","\n","  #print(train_feats.shape)\n","  #print(val_feats.shape)\n"," \n","  if( model_name == 'knn') :\n","    k_range = model_hypers['k_range']\n","    bestScore = -1\n","    bestK = -1\n","    for k in k_range:     \n","      model = KNeighborsClassifier(n_neighbors=k)\n","      model.fit(train_feats,train_labels)\n","      y_pred = model.predict(val_feats)      \n","      f1Score =  f1_score(val_labels, y_pred,average='micro')    \n","      print(\"KNN: k=\"+str(k)+\" f1 score=\"+fmtF1Score(f1Score)) \n","      if f1Score > bestScore :\n","         bestScore = f1Score\n","         bestK= k\n","    best_val_scores = bestScore \n","    best_val_model_params = bestK\n","  elif( model_name == 'svm') :  \n","    C = model_hypers['C']\n","    gamma = model_hypers['gamma']\n","    kernels = model_hypers['kernel']\n","    degree = model_hypers['degree']\n","    bestScore = -1  \n","    best_params = {}\n","    best_kernel = ''\n","    for k in kernels:\n","      if ( k == 'rbf'):\n","        for c in C:\n","          for g in gamma:\n","            model = SVC(kernel='rbf', probability=True, C=c, gamma=g)\n","            model.fit(train_feats,train_labels)\n","            y_pred = model.predict(val_feats)      \n","            f1Score =  f1_score(val_labels, y_pred,average='micro')\n","            \n","            print('SVM: kernel='+k+';c='+str(C)+';gamma='+str(g)+';score='+fmtF1Score(f1Score))\n","            if f1Score > bestScore :\n","              bestScore = f1Score              \n","              best_params['C'] = c\n","              best_params['gamma'] = g\n","              best_params['kernel'] = k\n","              #print(confusion_matrix(val_labels, y_pred))\n","              #best_params['confmatrix'] = confusion_matrix(val_labels, y_pred)\n","              \n","      elif (k == 'poly'):\n","        for d in degree:\n","          model = SVC(kernel=k, degree=d)\n","          model.fit(train_feats,train_labels)\n","          y_pred = model.predict(val_feats)      \n","          f1Score =  f1_score(val_labels, y_pred,average='micro')\n","          print('SVM: kernel='+k+';d='+str(d)+';score='+fmtF1Score(f1Score))\n","          if f1Score > bestScore :\n","            bestScore = f1Score\n","            best_params['kernel'] = k\n","            best_params['degree'] = d\n","            \n","      else:\n","        model = SVC(kernel=k,gamma='auto')\n","        model.fit(train_feats,train_labels)\n","        y_pred = model.predict(val_feats)       \n","        f1Score =  f1_score(val_labels, y_pred,average='micro')\n","        print('SVM: kernel=sigmoid;score='+fmtF1Score(f1Score))\n","        if f1Score > bestScore :\n","          bestScore = f1Score\n","          best_params['kernel'] = k\n","          \n","\n","    best_val_scores = bestScore \n","    best_val_model_params = best_params\n","    #print('svm-BEST-score:'+str(best_val_scores))\n","    #print(best_params)\n","  elif( model_name == 'xgboost') :\n","    model = XGBClassifier()  \n","    model.fit(train_feats,train_labels)\n","    y_pred = model.predict(val_feats)      \n","    best_val_scores =  f1_score(val_labels, y_pred,average='micro')\n","  elif( model_name == 'lightgbm') :\n","    model = LGBMClassifier()  \n","    model.fit(train_feats,train_labels)\n","    y_pred = model.predict(val_feats)      \n","    best_val_scores =  f1_score(val_labels, y_pred,average='micro')\n","  elif( model_name == 'mlp') :\n","    bestScore = -1\n","    best_params = [0]\n","    h_lists = model_hypers['h'] \n","    for h in h_lists:\n","      hn = np.array(h)      \n","      num_inputs = np.shape(train_feats)[1]   #get the number of columns in the trainig features\n","      hn = np.ceil(hn * num_inputs)           #get celing of the input element\n","      hn = hn.astype(int)                     #casting the object as int only\n","      hnt = tuple(hn)                  \n","      model = MLPClassifier(hidden_layer_sizes=hnt, activation='relu', solver='adam', max_iter=500) \n","      model.fit(train_feats,train_labels)      \n","      y_pred = model.predict(val_feats)         \n","      f1Score =  f1_score(val_labels, y_pred,average='micro')      \n","      print('MLP: params='+str(h)+';score='+fmtF1Score(f1Score))\n","      if f1Score > bestScore :\n","        bestScore = f1Score\n","        best_params = h          \n","\n","    best_val_scores = bestScore\n","    best_val_model_params = best_params\n","\n","\n","  return (best_val_scores,best_val_model_params)"],"metadata":{"id":"dEDWXVP69O19"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC \n","from xgboost import XGBClassifier\n","from lightgbm import LGBMClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n","\n","def test_on_combined_train_val(model_name,best_val_model_params,train_feats,train_labels,test_feats,test_labels):\n","  final_test_score = 0\n","  final_model = []\n","\n","  #print(train_feats.shape)\n","  #print(test_feats.shape)\n","   \n","  if( model_name == 'knn') :\n","    k = best_val_model_params\n","    model = KNeighborsClassifier(n_neighbors=k)  \n","  elif( model_name == 'svm') :\n","      if(best_val_model_params['kernel'] == 'rbf'):\n","          c = best_val_model_params['C']\n","          g = best_val_model_params['gamma']\n","          model = SVC(kernel='rbf', probability=True, C=c, gamma=g)  \n","      elif (best_val_model_params['kernel'] == 'poly'):\n","        d = best_val_model_params['degree']\n","        model = SVC(kernel='poly', degree=d)        \n","      else: #(best_val_model_params['kernel'] == 'sigmoid')\n","        model = SVC(kernel='sigmoid',gamma='auto')\n","  elif( model_name == 'xgboost') :\n","    model = XGBClassifier()  \n","  elif( model_name == 'lightgbm') :        \n","    model = LGBMClassifier()  \n","  elif( model_name == 'mlp') :    \n","    h = best_val_model_params\n","    hn = np.array(h)      \n","    num_inputs = np.shape(test_feats)[1]\n","    hn = np.ceil(hn * num_inputs)\n","    hn = hn.astype(int)      \n","    hnt = tuple(hn)                  \n","    model = MLPClassifier(hidden_layer_sizes=hnt, activation='relu', solver='adam', max_iter=1000) \n","\n","  model.fit(train_feats,train_labels)    \n","  y_pred = model.predict(test_feats)      \n","  print(confusion_matrix(test_labels, y_pred))\n","  final_test_score =  f1_score(test_labels, y_pred,average='micro')     \n","  final_model = model    \n","   \n","  return (final_test_score,final_model)"],"metadata":{"id":"OARRlAobGEot"},"execution_count":null,"outputs":[]}]}